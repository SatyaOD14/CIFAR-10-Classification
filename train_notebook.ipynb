{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7c7b29",
   "metadata": {},
   "source": [
    "# CIFAR-10 Image Classification\n",
    "\n",
    "**Models:** Baseline CNN, ResNet-18 (transfer learning), EfficientNet-B0 (timm)\n",
    "\n",
    "**Author:** Satya Narayan Mohanty\n",
    "\n",
    "**University:** KIIT Deemed to be University\n",
    "\n",
    "**Guide:** Mr. N Biraja Isac\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f669a2b",
   "metadata": {},
   "source": [
    "## 1. Setup & Environment\n",
    "\n",
    "This notebook contains full code to train and evaluate three models on the CIFAR-10 dataset. It is designed to run on a machine with a CUDA-capable GPU. Use the provided `requirements.txt` to create a conda/venv environment.\n",
    "\n",
    "Files created in `/mnt/data/CIFAR10_Image_Classification_Project`:\n",
    "- `train_notebook.ipynb` (this notebook)\n",
    "- `requirements.txt`\n",
    "- `README.md`\n",
    "- `models/` (directory where trained model `.pth` files will be saved)\n",
    "\n",
    "Run-time note: Training from scratch can take several hours depending on hardware. You can reduce epochs or use smaller batch sizes for quick tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435dac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and helper functions\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617499de",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "We will use standard CIFAR-10 from `torchvision.datasets`. We apply typical augmentations used for CIFAR training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms and loaders\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "classes = trainset.classes\n",
    "print('Classes:', classes)\n",
    "print('Train samples:', len(trainset), 'Test samples:', len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937626cd",
   "metadata": {},
   "source": [
    "## 3. Baseline CNN Model\n",
    "\n",
    "A simple CNN with 3 conv blocks and 2 FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0fde5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,64,3,padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64,64,3,padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128,128,3,padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(128,256,3,padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256*4*4,512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512,num_classes)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# quick instantiation + parameter count\n",
    "model = BaselineCNN().to(device)\n",
    "def count_params(m): return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "print('BaselineCNN params:', count_params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b47599",
   "metadata": {},
   "source": [
    "## 4. ResNet-18 (Transfer Learning)\n",
    "\n",
    "We load a ResNet-18 pretrained on ImageNet and modify the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab20f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "# modify final fc for CIFAR-10\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\n",
    "resnet18 = resnet18.to(device)\n",
    "print('ResNet-18 params:', count_params(resnet18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa452dc",
   "metadata": {},
   "source": [
    "## 5. EfficientNet-B0 (via timm)\n",
    "\n",
    "We use `timm` to load EfficientNet-B0 pretrained weights and adjust classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3595ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet via timm\n",
    "try:\n",
    "    import timm\n",
    "    efficient = timm.create_model('efficientnet_b0', pretrained=True, num_classes=10)\n",
    "    efficient = efficient.to(device)\n",
    "    print('EfficientNet-B0 params:', count_params(efficient))\n",
    "except Exception as e:\n",
    "    print('timm not installed. To use EfficientNet install timm via pip: pip install timm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7577c0",
   "metadata": {},
   "source": [
    "## 6. Training Utilities\n",
    "\n",
    "Training loop, evaluation, and save/load helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a7503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation utilities\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in tqdm(loader, leave=False):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(targets).sum().item()\n",
    "        total += inputs.size(0)\n",
    "    return running_loss/total, correct/total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(targets).sum().item()\n",
    "            total += inputs.size(0)\n",
    "    return running_loss/total, correct/total\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print('Saved model to', path)\n",
    "\n",
    "def load_model_state(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    print('Loaded model from', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cecb550",
   "metadata": {},
   "source": [
    "## 7. Example Training Run (Baseline CNN)\n",
    "\n",
    "Below is an example of training code. Uncomment and run to start training. For quick experimentation reduce `num_epochs` to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ebdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training run (uncomment to run)\n",
    "# model = BaselineCNN().to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "# num_epochs = 50\n",
    "# best_acc = 0.0\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss, train_acc = train_epoch(model, trainloader, criterion, optimizer, device)\n",
    "#     val_loss, val_acc = evaluate(model, testloader, criterion, device)\n",
    "#     scheduler.step()\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs} - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "#     if val_acc > best_acc:\n",
    "#         best_acc = val_acc\n",
    "#         save_model(model, f'models/baseline_cnn_best.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43757f29",
   "metadata": {},
   "source": [
    "## 8. Evaluation & Visualization\n",
    "\n",
    "Code to compute confusion matrix and plot some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d1edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix and some predictions (example helper code)\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def get_all_preds(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, p = outputs.max(1)\n",
    "            preds.append(p.cpu().numpy())\n",
    "            targets.append(labels.numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    return preds, targets\n",
    "\n",
    "# Example usage (after loading/saving models)\n",
    "# load_model_state(model, 'models/baseline_cnn_best.pth', device)\n",
    "# preds, targets = get_all_preds(model, testloader, device)\n",
    "# cm = confusion_matrix(targets, preds)\n",
    "# print(classification_report(targets, preds, target_names=classes))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes)\n",
    "# plt.xlabel('Predicted'); plt.ylabel('True'); plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
